{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4f64a63",
   "metadata": {},
   "source": [
    "## *Entrega do Plano de Projeto Mineração de Dados*\n",
    "Uma grande loja de varejo forneceu um conjunto abrangente de dados históricos de vendas de três lojas, que inclui informações como data, produto, categoria, quantidade vendida, preço unitário e vendas totais. O objetivo deste projeto é extrair insights relevantes que possam auxiliar a gestão na tomada de decisões estratégicas – como otimização do mix de produtos, controle de estoque, definição de promoções e análise de desempenho financeiro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526a250b",
   "metadata": {},
   "source": [
    "### Bibliotecas usadas neste Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00bc77d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e94870",
   "metadata": {},
   "source": [
    "### 1.1 Importando os três datasets das lojas\n",
    "Para carregar um dataset no formato csv, basta utilizar a função `read_csv` do pandas. Por padrão, ela considera _','_ como separador. Substituímos _','_ por _';'_ !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ba31ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loja1 = pd.read_csv(\"Dataset_6_V_loja 01.csv\", sep=\";\")\n",
    "loja2 = pd.read_csv(\"Dataset_6_V_loja 02.csv\", sep=\";\")\n",
    "loja3 = pd.read_csv(\"Dataset_6_V_loja 03.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5dd14f",
   "metadata": {},
   "source": [
    "### 1.2 Conferindo as informações das três planilhas\n",
    "Usando um laço for a gente nomeia cada dataset atribuindo eles aos seus respectivos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf334dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df, name in [(loja1, 'Loja1'), (loja2, 'Loja2'), (loja3, 'Loja3')]:\n",
    "    df[\"Loja\"] = name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f021c23",
   "metadata": {},
   "source": [
    "### 1.3 Concatenando todos os dataframes em um só\n",
    "Atribuindo á váriavel 'dados' os três df das lojas usando uma função da biblioteca e reorganizando o índice deles com o argumento _'ignore_index=True'_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8cce77",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.concat([loja1, loja2, loja3], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfa1f01",
   "metadata": {},
   "source": [
    "### 1.4 Filtrando as colunas mais interessantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f7e6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = dados[[\n",
    "    \"Data\", \"Produto\", \"Categoria\",\n",
    "    \"Quantidade Vendida\", \"Preço Unitário\",\n",
    "    \"Total de Vendas\", \"Loja\"\n",
    "]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490ff100",
   "metadata": {},
   "source": [
    "### 1.5 Verificando o total de linhas iniciais!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99883727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- INÍCIO: 3000 linhas carregadas ---\n"
     ]
    }
   ],
   "source": [
    "LINHAS_INICIAIS = len(dados)\n",
    "print(f\"\\n--- INÍCIO: {LINHAS_INICIAIS} linhas carregadas ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dbc155",
   "metadata": {},
   "source": [
    "### 1.6 Tratando as colunas numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d18506",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_numericas = [\"Quantidade Vendida\", \"Preço Unitário\", \"Total de Vendas\"]\n",
    "\n",
    "for col in cols_numericas:\n",
    "    # Garante que é string, troca vírgula por ponto, converte para float\n",
    "    dados[col] = dados[col].astype(str).str.replace(',', '.').apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dbf767",
   "metadata": {},
   "source": [
    "### 1.7 Limpeza de Texto (Strip)\n",
    "Remover espaços em branco extras é crucial para evitar que o Pandas conte o mesmo item duas vezes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8819300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"Produto\", \"Categoria\", \"Loja\"]:\n",
    "    dados[col] = dados[col].str.strip().astype(\"string\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2eb159",
   "metadata": {},
   "source": [
    "### 1.8 Corrigindo a DATA, no código anterior o programa eliminava cerca de 60% do DF só pelo formato das datas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82d317a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linhas com data inválida (removidas): 0\n"
     ]
    }
   ],
   "source": [
    "# dayfirst=True é o segredo para datas brasileiras (DD/MM/AAAA)!!!\n",
    "dados[\"Data\"] = pd.to_datetime(dados[\"Data\"], dayfirst=True, errors=\"coerce\")\n",
    "\n",
    "# Verifica perda\n",
    "nulos_data = dados[\"Data\"].isna().sum()\n",
    "print(f\"Linhas com data inválida (removidas): {nulos_data}\")\n",
    "dados = dados.dropna(subset=[\"Data\"])\n",
    "\n",
    "# Cria coluna Mês para a imputação\n",
    "dados['Mes'] = dados['Data'].dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d55efdc",
   "metadata": {},
   "source": [
    "### 1.9 Imputação Condicional (primeira fase)\n",
    "Esta parte evita a exclusão de linhas com dados faltando. Em vez de deletar, você preenche os buracos com o valor mais provável!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488ce0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realizando Imputação...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\megaf\\AppData\\Local\\Temp\\ipykernel_35076\\1111022557.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dados[col].fillna(valor_imputacao, inplace=True)\n",
      "C:\\Users\\megaf\\AppData\\Local\\Temp\\ipykernel_35076\\1111022557.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dados[col].fillna(dados[col].median(), inplace=True)\n",
      "C:\\Users\\megaf\\AppData\\Local\\Temp\\ipykernel_35076\\1111022557.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dados[col].fillna(valor_imputacao, inplace=True)\n",
      "C:\\Users\\megaf\\AppData\\Local\\Temp\\ipykernel_35076\\1111022557.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dados[col].fillna(dados[col].median(), inplace=True)\n",
      "C:\\Users\\megaf\\AppData\\Local\\Temp\\ipykernel_35076\\1111022557.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dados[col].fillna(valor_imputacao, inplace=True)\n",
      "C:\\Users\\megaf\\AppData\\Local\\Temp\\ipykernel_35076\\1111022557.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dados[col].fillna(dados[col].median(), inplace=True)\n",
      "C:\\Users\\megaf\\AppData\\Local\\Temp\\ipykernel_35076\\1111022557.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dados[col].fillna('Ausente', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Realizando Imputação...\")\n",
    "\n",
    "# Preenche vazios numéricos com a MEDIANA do grupo (Mês + Loja)\n",
    "for col in cols_numericas:\n",
    "    valor_imputacao = dados.groupby(['Mes', 'Loja'])[col].transform('median')\n",
    "    dados[col].fillna(valor_imputacao, inplace=True)\n",
    "    # Se sobrar algo, usa mediana geral\n",
    "    dados[col].fillna(dados[col].median(), inplace=True)\n",
    "\n",
    "# Preenche vazios de texto\n",
    "for col in [\"Produto\", \"Categoria\"]:\n",
    "    dados[col].fillna('Ausente', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6d19a5",
   "metadata": {},
   "source": [
    "### 1.10 Remoção de Outliers com Z-Score\n",
    "Em vez de decidir por conta própria que a quantidade máxima é 500, você deixa a estatística definir o que é um valor outlier (O Z-score é um cálculo que mede o quão longe um valor está da média)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aa8927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrando Outliers estatísticos (Z-Score > 4)...\n"
     ]
    }
   ],
   "source": [
    "LIMITE_ZSCORE = 4 \n",
    "\n",
    "print(f\"Filtrando Outliers estatísticos (Z-Score > {LIMITE_ZSCORE})...\")\n",
    "\n",
    "for col in cols_numericas:\n",
    "    # Calcula Z-Score\n",
    "    media = dados[col].mean()\n",
    "    std = dados[col].std()\n",
    "    \n",
    "    # Cria coluna temporária\n",
    "    dados[f\"ZScore_{col}\"] = (dados[col] - media) / std\n",
    "    \n",
    "    # Filtra (mantém o que está dentro do limite)\n",
    "    dados = dados.loc[\n",
    "        (dados[f\"ZScore_{col}\"] >= -LIMITE_ZSCORE) & \n",
    "        (dados[f\"ZScore_{col}\"] <= LIMITE_ZSCORE)\n",
    "    ]\n",
    "    # Remove coluna temporária\n",
    "    dados = dados.drop(columns=[f\"ZScore_{col}\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7179ef",
   "metadata": {},
   "source": [
    "### 1.11 Filtro de Integridade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beadde82",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = dados.loc[\n",
    "    (dados[\"Preço Unitário\"] > 0) & \n",
    "    (dados[\"Quantidade Vendida\"] > 0) &\n",
    "    (dados[\"Total de Vendas\"] >= 0)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a786e88a",
   "metadata": {},
   "source": [
    "### 1.12 Finalização!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14073d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------\n",
      "✅ RESULTADO FINAL (FASE PRÉ-PROCESSAMENTO)\n",
      "-------------------------------------------\n",
      "Linhas Originais: 3000\n",
      "Linhas Finais:    2996\n",
      "Aproveitamento:   99.87%\n",
      "\n",
      "Estrutura final (info):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2996 entries, 0 to 2995\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   Data                2996 non-null   datetime64[ns]\n",
      " 1   Produto             2996 non-null   string        \n",
      " 2   Categoria           2996 non-null   string        \n",
      " 3   Quantidade Vendida  2996 non-null   float64       \n",
      " 4   Preço Unitário      2996 non-null   float64       \n",
      " 5   Total de Vendas     2996 non-null   float64       \n",
      " 6   Loja                2996 non-null   string        \n",
      "dtypes: datetime64[ns](1), float64(3), string(3)\n",
      "memory usage: 164.0 KB\n",
      "None\n",
      "\n",
      "Estatísticas Descritivas (describe):\n",
      "                                Data  Quantidade Vendida  Preço Unitário  \\\n",
      "count                           2996         2996.000000     2996.000000   \n",
      "mean   2024-09-22 12:38:55.914553088           52.425401     1671.528705   \n",
      "min              2024-01-01 00:00:00            1.000000      800.000000   \n",
      "25%              2024-06-22 00:00:00           25.000000     1000.000000   \n",
      "50%              2024-09-22 00:00:00           52.000000     1500.000000   \n",
      "75%              2024-12-21 00:00:00           78.000000     2200.000000   \n",
      "max              2025-05-02 00:00:00          120.000000     3000.000000   \n",
      "std                              NaN           31.013307      726.310088   \n",
      "\n",
      "       Total de Vendas  \n",
      "count      2996.000000  \n",
      "mean      87764.485981  \n",
      "min           0.000000  \n",
      "25%       36000.000000  \n",
      "50%       72000.000000  \n",
      "75%      121275.000000  \n",
      "max      360000.000000  \n",
      "std       69779.256192  \n",
      "\n",
      "Dados exportados para dataset_tratado.csv\n"
     ]
    }
   ],
   "source": [
    "dados = dados.drop(columns=['Mes'], errors='ignore')\n",
    "dados = dados.reset_index(drop=True)\n",
    "\n",
    "LINHAS_FINAIS = len(dados)\n",
    "LINHAS_INICIAIS = 3000 # Valor fixo de referência\n",
    "PORCENTAGEM_RETIDA = (LINHAS_FINAIS / LINHAS_INICIAIS) * 100\n",
    "\n",
    "print(\"\\n-------------------------------------------\")\n",
    "print(\"✅ RESULTADO FINAL (FASE PRÉ-PROCESSAMENTO)\")\n",
    "print(\"-------------------------------------------\")\n",
    "print(f\"Linhas Originais: {LINHAS_INICIAIS}\")\n",
    "print(f\"Linhas Finais:    {LINHAS_FINAIS}\")\n",
    "print(f\"Aproveitamento:   {PORCENTAGEM_RETIDA:.2f}%\")\n",
    "\n",
    "print(\"\\nEstrutura final (info):\")\n",
    "print(dados.info())\n",
    "\n",
    "print(\"\\nEstatísticas Descritivas (describe):\")\n",
    "print(dados.describe())\n",
    "\n",
    "# Exporta o dataset tratado e limpo\n",
    "dados.to_csv(\"dataset_tratado.csv\", index=False) \n",
    "print(\"\\nDados exportados para dataset_tratado.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
