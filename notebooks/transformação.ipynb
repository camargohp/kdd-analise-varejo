{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ff5364d",
   "metadata": {},
   "source": [
    "# ETAPA DE TRANSFORMAÇÃO + MINERAÇÃO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf55cc32",
   "metadata": {},
   "source": [
    "### 1. Carregar o dataset tratado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb30fd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CARREGAR O ARQUIVO TRATADO\n",
    "dados = pd.read_excel(\"dataset_tratado.xlsx\")\n",
    "\n",
    "print(\"Dataset carregado!\")\n",
    "dados.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c789ac",
   "metadata": {},
   "source": [
    "### 2. Criar atributos temporais\n",
    "- Datas são úteis para análise\n",
    "- Criamos colunas novas como mês, ano, semana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519b8253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mesmo que tenhamos feito antes, ao salvar e carregar de novo (em CSV),\n",
    "# o Pandas transforma a coluna 'Data' em texto (string).\n",
    "# Precisamos garantir que ela seja do tipo datetime para trabalhar com datas.\n",
    "dados[\"Data\"] = pd.to_datetime(dados[\"Data\"])\n",
    "\n",
    "print(f\"Dataset carregado com {len(dados)} linhas.\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# EXTRAÇÃO DE ATRIBUTOS DE TEMPO\n",
    "print(\"2. Criando Atributos de Tempo...\")\n",
    "\n",
    "# CRIAÇÃO DE ATRIBUTOS DE TEMPO\n",
    "dados['Ano'] = dados['Data'].dt.year\n",
    "dados['Mes'] = dados['Data'].dt.month\n",
    "dados['Dia_do_Mes'] = dados['Data'].dt.day\n",
    "dados['Dia_Semana_Nome'] = dados['Data'].dt.day_name(locale='pt_BR') # Nome do dia da semana (ex: 'Sábado')\n",
    "dados['Semana_Ano'] = dados['Data'].dt.isocalendar().week.astype(int) # Número da semana no ano\n",
    "\n",
    "display(dados.head())\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a01da0",
   "metadata": {},
   "source": [
    "### 3. Engenharia de Atributos Financeiros\n",
    "Criando o Ticket Médio por Item/Transação. O \"Ticket Médio\" é o valor total de venda. Vamos garantir que temos o cálculo correto (embora o seu dataset já tenha o Total de Vendas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebf8dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRIAÇÃO DO TICKET MÉDIO DA TRANSAÇÃO\n",
    "print(\"3. Criando Atributo de Valor Financeiro (Ticket Médio/Rentabilidade)...\")\n",
    "\n",
    "# A coluna 'Total de Vendas' já é o Ticket Médio da transação.\n",
    "# Para fins de checagem e garantir que todos os dados fazem sentido:\n",
    "dados['Total_Vendas_Calculado'] = dados['Quantidade Vendida'] * dados['Preço Unitário']\n",
    "\n",
    "# Verificamos a diferença entre o valor registrado e o calculado.\n",
    "# Essa diferença deve ser zero ou muito próxima de zero se os dados estiverem perfeitos.\n",
    "dados['Diferenca_Vendas'] = dados['Total de Vendas'] - dados['Total_Vendas_Calculado']\n",
    "\n",
    "# O 'Total de Vendas' será nossa principal métrica de valor da transação.\n",
    "# Vamos criar uma cópia dela com um nome mais simples para análise futura.\n",
    "dados['Ticket_Transacao'] = dados['Total de Vendas']\n",
    "\n",
    "dados[['Quantidade Vendida', 'Preço Unitário', 'Total de Vendas', 'Total_Vendas_Calculado', 'Diferenca_Vendas']].head()\n",
    "\n",
    "display(dados.head())\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ef8a2b",
   "metadata": {},
   "source": [
    "### 4. Transformação: Codificação (Encoding) de Variáveis Categóricas\n",
    "Algoritmos de Mineração de Dados (como Regressão e Clustering) só entendem números. Precisamos transformar texto (como Dia_Semana_Nome ou Loja) em números.\n",
    "Codificação One-Hot Encoding (Variáveis com poucas categorias)\n",
    "Usamos pd.get_dummies() para variáveis que têm poucos valores únicos, como Loja e Dia_Semana_Nome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20bdf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1. One-Hot Encoding para Loja e Dia da Semana\n",
    "print(\"4.1. Aplicando One-Hot Encoding em 'Loja' e 'Dia_Semana_Nome'...\")\n",
    "\n",
    "# Loja: Cria 3 novas colunas (Loja_Loja1, Loja_Loja2, Loja_Loja3) com 0 ou 1\n",
    "# Dia: Cria 7 novas colunas (Dia_Domingo, Dia_Segunda, etc.) com 0 ou 1\n",
    "dados_codificado = pd.get_dummies(dados, columns=['Loja', 'Dia_Semana_Nome'], prefix=['Loja', 'Dia'])\n",
    "\n",
    "print(\"Colunas criadas pelo One-Hot Encoding:\")\n",
    "print([col for col in dados_codificado.columns if 'Loja_' in col or 'Dia_' in col])\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fc6aeb",
   "metadata": {},
   "source": [
    "### 4.2. Codificação por Frequência (Frequency Encoding) (Variáveis com muitas categorias)\n",
    "Para variáveis como Produto ou Categoria, que podem ter centenas de valores, o One-Hot Encoding cria muitas colunas desnecessárias. Em vez disso, transformamos o texto na frequência com que ele aparece no dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3eb38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2. Frequency Encoding para Categoria\n",
    "print(\"4.2. Aplicando Frequency Encoding em 'Categoria'...\")\n",
    "\n",
    "# 1. Contamos quantas vezes cada Categoria aparece e normalizamos (transformamos em porcentagem)\n",
    "frequencia_categoria = dados_codificado['Categoria'].value_counts(normalize=True)\n",
    "\n",
    "# 2. Criamos uma nova coluna mapeando o nome da Categoria pela sua frequência (porcentagem)\n",
    "dados_codificado['Categoria_Freq'] = dados_codificado['Categoria'].map(frequencia_categoria)\n",
    "\n",
    "print(f\"O produto da categoria '{dados_codificado['Categoria'].iloc[0]}' tem frequência de {dados_codificado['Categoria_Freq'].iloc[0]:.4f}\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b292c21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Finalização da Transformação\n",
    "print(\"5. Finalizando e salvando o dataset transformado...\")\n",
    "\n",
    "# A lista de colunas a remover deve ser ajustada:\n",
    "colunas_a_remover = [\n",
    "    'Data',                 # Coluna datetime (usada apenas para extração)\n",
    "    'Produto',              # Coluna de texto (não codificada)\n",
    "    'Categoria',            # Coluna de texto (mas já criamos a Categoria_Freq)\n",
    "    'Total_Vendas_Calculado', # Coluna temporária de checagem\n",
    "    'Diferenca_Vendas'      # Coluna temporária de checagem\n",
    "    # 'Dia_Semana_Nome' e 'Loja' NÃO ESTÃO MAIS AQUI, pois foram removidas pelo get_dummies()\n",
    "]\n",
    "\n",
    "# Usamos errors='ignore' para garantir que o código não quebre se, por acaso, alguma coluna já tiver sido removida.\n",
    "dados_finais = dados_codificado.drop(columns=colunas_a_remover, errors='ignore')\n",
    "\n",
    "# Vamos salvar o dataset final para a Mineração\n",
    "dados_finais.to_csv(\"dataset_transformado.csv\", index=False)\n",
    "\n",
    "print(\"\\n-------------------------------------------\")\n",
    "print(\"✅ FASE DE TRANSFORMAÇÃO CONCLUÍDA\")\n",
    "print(f\"Dataset final para Mineração tem {len(dados_finais.columns)} colunas.\")\n",
    "print(\"Arquivo 'dataset_transformado.csv' salvo com sucesso.\")\n",
    "print(\"-------------------------------------------\")\n",
    "dados_finais.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
